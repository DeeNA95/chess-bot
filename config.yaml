# Algorithm Selection: 'mcts', 'grpo', 'ppo', 'ppo_mcts', "grpo_mcts"
algorithm: "ppo_mcts"

# Reward Settings
rewards:
  stockfish_path: "/usr/games/stockfish"
  stockfish_depth: 10
  stockfish_hash: 512
  num_workers: 12
  stockfish_weight: 0.7
  material_weight: 0.2
  outcome_weight: 0.1

# General Training Settings
training:
  total_games: 100000
  batch_size: 4096
  games_per_update: 4096
  lr: 0.0001
  checkpoint_dir: "./checkpoints"
  buffer_capacity: 600000
  num_parallel_games: 512
  device: "cuda"  # 'cpu', 'cuda', 'mps' (auto-detected if cleaner)

# MCTS Specific Settings
mcts:
  num_simulations: 1200
  c_puct: 1.5
  temperature: 1.0
  dirichlet_alpha: 0.03
  dirichlet_epsilon: 0.25

# GRPO Specific Settings
grpo:
  group_size: 16      # G in GRPO paper (outcomes sampled per state)
  epsilon: 0.2        # Clipping parameter
  beta_kl: 0.01       # KL penalty coefficient
  entropy_coef: 0.01  # Entropy bonus

# PPO Specific Settings
ppo:
  clip_ratio: 0.2
  value_coef: 0.5
  entropy_coef: 0.01
  gae_lambda: 0.95
  gamma: 0.99
  ppo_epochs: 4
